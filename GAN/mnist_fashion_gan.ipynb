{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist_fashion_gan.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "XUeX26gHSK72"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Generative Adversarial Networks"
      ],
      "metadata": {
        "id": "HTuyJGSEn3gg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MNIST-fashion GAN\n",
        "The Fashion-MNIST dataset contains 60,000 training images (and 10,000 test images) of fashion and clothing items, taken from 10 classes. Each image is a standardized 28Ã—28 size in grayscale (784 total pixels).\n",
        "\n",
        "<center>\n",
        "<img src=\"https://miro.medium.com/max/1400/0*ga9XgppZI_XULBRz\">\n",
        "</center>"
      ],
      "metadata": {
        "id": "XUeX26gHSK72"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Libraries"
      ],
      "metadata": {
        "id": "xEDAN1Xcos7A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, InputLayer, Conv2D, Dropout, Convolution2DTranspose, Reshape, Flatten\n",
        "from tensorflow.keras.models import Sequential \n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "from tensorflow.keras.metrics import BinaryAccuracy\n",
        "import numpy as np\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from matplotlib import pyplot as plt\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "metadata": {
        "id": "2zWxbme7o5wj"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check the GPU of your machine (Tesla P100 is the highest you can get)"
      ],
      "metadata": {
        "id": "DqUmYpqVsnLm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "4blw1qPttTZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Num GPUs Available \", len(tf.config.list_physical_devices('GPU')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MyuvxYEbsWHZ",
        "outputId": "10ccd4bf-f487-4857-f838-fc96399c3748"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available  1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the Fashion MNIST Dataset"
      ],
      "metadata": {
        "id": "2Kb_O7LYoHuY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "8QHwbBY3nLbj"
      },
      "outputs": [],
      "source": [
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing"
      ],
      "metadata": {
        "id": "gbvDs5peqhHM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Merge the training and testing sets, Then normalize the images from [0,255] to [0,1]"
      ],
      "metadata": {
        "id": "NDKnrocppNhQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = np.concatenate([x_train, x_test], axis = 0)\n",
        "print(dataset.shape)\n",
        "dataset = np.expand_dims(dataset, -1).astype(\"float32\") / 255"
      ],
      "metadata": {
        "id": "9F62c76qoplR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will reshape the data to dimensions needed by the CNN layers that's why we convert it to TensorFlow type. After that we will shuffle and batch it."
      ],
      "metadata": {
        "id": "WUN5-GNuqz6E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "dataset = tf.data.Dataset.from_tensor_slices(dataset)\n",
        "dataset = dataset.shuffle(buffer_size=1024).batch(BATCH_SIZE)"
      ],
      "metadata": {
        "id": "adNiHEVUrE7s"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building The Generator\n",
        "The generator's input is a noise vector. "
      ],
      "metadata": {
        "id": "ov1NVhxOw8uA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NOISE_DIM = 150\n",
        "\n",
        "generator = Sequential ([\n",
        "      InputLayer(input_shape=(NOISE_DIM,)),\n",
        "      Dense(7*7*256),\n",
        "      Reshape(target_shape=(7, 7, 256)),\n",
        "      Convolution2DTranspose(256, 3, activation=\"LeakyReLU\", strides=2, padding=\"same\"),\n",
        "      Convolution2DTranspose(128, 3, activation=\"LeakyReLU\", strides=2, padding=\"same\"),\n",
        "      Convolution2DTranspose(1, 3, activation=\"sigmoid\", padding=\"same\")\n",
        "])\n",
        "\n",
        "generator.summary()"
      ],
      "metadata": {
        "id": "SO2d84smw5_J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building The Discriminator"
      ],
      "metadata": {
        "id": "Ud2_Yrw_m25z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator = Sequential ([\n",
        "      InputLayer(input_shape=((28, 28, 1))),\n",
        "      Conv2D(256, 3, activation=\"relu\", strides=2, padding=\"same\"),\n",
        "      Conv2D(128, 3, activation=\"relu\", strides=2, padding=\"same\"),\n",
        "      Flatten(),\n",
        "      Dense(64, activation=\"relu\"),\n",
        "      Dropout(0.2),\n",
        "      Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "discriminator.summary()"
      ],
      "metadata": {
        "id": "9j6exCXMm02W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimizers"
      ],
      "metadata": {
        "id": "809gt_Lio8X4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer_g = Adam(learning_rate=0.00001, beta_1=0.5)\n",
        "optimizer_d = Adam(learning_rate=0.00003, beta_1=0.5)\n",
        "\n",
        "loss_func = BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "g_acc_metric = BinaryAccuracy()\n",
        "d_acc_metric = BinaryAccuracy()"
      ],
      "metadata": {
        "id": "_5n34g4Eo4lU"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set Up Discriminator Training"
      ],
      "metadata": {
        "id": "_w30MGtirIb4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_d_step(data):\n",
        "  \"\"\" train func\"\"\"\n",
        "  batch_size = tf.shape(data)[0]\n",
        "\n",
        "  noise =  tf.random.normal(shape=(batch_size, NOISE_DIM))\n",
        "\n",
        "  y_true = tf.concat(\n",
        "      [\n",
        "       tf.ones(batch_size, 1),\n",
        "       tf.zeros(batch_size, 1)\n",
        "      ], axis = 0\n",
        "  )\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    fake = generator(noise)\n",
        "    x = tf.concat([data, fake], axis=0)\n",
        "    y_pred = discriminator(x) # D(x)\n",
        "    discriminator_loss = loss_func(y_true,  y_pred)\n",
        "\n",
        "  grads = tape.gradient(discriminator_loss, discriminator.trainable_weights)\n",
        "  optimizer_d.apply_gradients(zip(grads, discriminator.trainable_weights))\n",
        "\n",
        "  d_acc_metric.update_state(y_true, y_pred)\n",
        "\n",
        "  visualization_loss = {\n",
        "      'discriminator_loss' : discriminator_loss,\n",
        "      'discriminator_acc' : d_acc_metric.result()\n",
        "  }\n",
        "\n",
        "  return visualization_loss\n"
      ],
      "metadata": {
        "id": "PrZeH6tsrLGV"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set Up Generator Training"
      ],
      "metadata": {
        "id": "aCm2OLEjvo4Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_g_step(data):\n",
        "  \"\"\" train func\"\"\"\n",
        "  batch_size = tf.shape(data)[0]\n",
        "\n",
        "  noise =  tf.random.normal(shape=(batch_size, NOISE_DIM))\n",
        "\n",
        "  y_true = tf.ones(batch_size, 1)\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    y_pred = discriminator(generator(noise)) # D(G(Z))\n",
        "    generator_loss = loss_func(y_true,  y_pred)\n",
        "\n",
        "  grads = tape.gradient(generator_loss, generator.trainable_weights)\n",
        "  optimizer_g.apply_gradients(zip(grads, generator.trainable_weights))\n",
        "\n",
        "  g_acc_metric.update_state(y_true, y_pred)\n",
        "  visualization_loss = {\n",
        "      'generator_loss' : generator_loss,\n",
        "      'generator_acc' : g_acc_metric.result()\n",
        "  }\n",
        "  \n",
        "  return visualization_loss"
      ],
      "metadata": {
        "id": "vlLqdeguvpgr"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualization"
      ],
      "metadata": {
        "id": "jMBQdV_yydgN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_images(model):\n",
        "  \"\"\" visualize generated images as we train\"\"\"\n",
        "  images = model(np.random.normal(size=(81, NOISE_DIM)))\n",
        "\n",
        "  plt.figure(figsize=(9, 9))\n",
        "\n",
        "  for i, image in enumerate(images):\n",
        "    plt.subplot(9, 9, i+1)\n",
        "    plt.imshow(np.squeeze(image, -1), cmap=\"Greys_r\")\n",
        "    plt.axis('off')\n",
        "\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "okN6N9NZye5Q"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "gVCr6mrH0ADn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(30):\n",
        "\n",
        "  d_loss_sum = 0\n",
        "  d_acc_sum = 0\n",
        "  \n",
        "  g_loss_sum = 0\n",
        "  g_acc_sum = 0\n",
        "  \n",
        "  counter = 0\n",
        "\n",
        "  for batch in dataset:\n",
        "    d_loss = train_d_step(batch)\n",
        "\n",
        "    d_loss_sum += d_loss['discriminator_loss']\n",
        "    d_acc_sum += d_loss['discriminator_acc']\n",
        "\n",
        "    g_loss = train_g_step(batch)\n",
        "\n",
        "    g_loss_sum += g_loss['generator_loss']\n",
        "    g_acc_sum += g_loss['generator_acc']\n",
        "\n",
        "    counter += 1\n",
        "\n",
        "  print(\"Epoch:{} Loss G:{:0.4f}, Loss D:{:0.4f}, Acc G:%{:0.2f}, Acc D:%{:0.2f}\".format(\n",
        "      epoch,\n",
        "      g_loss_sum / counter,\n",
        "      d_loss_sum / counter,\n",
        "      100 * (g_acc_sum / counter),\n",
        "      100 * (d_acc_sum / counter),\n",
        "  ))\n",
        "  if epoch % 2 == 0:\n",
        "    plot_images(generator)"
      ],
      "metadata": {
        "id": "KZf2cc2Y0CZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test The Generator"
      ],
      "metadata": {
        "id": "RgAATyeAkOGD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "images = generator(np.random.normal(size=(81, NOISE_DIM)))\n",
        "\n",
        "plt.figure(figsize=(9, 9))\n",
        "\n",
        "for i, image in enumerate(images):\n",
        "  plt.subplot(9, 9, i+1)\n",
        "  plt.imshow(np.squeeze(image, -1), cmap=\"Greys_r\")\n",
        "  plt.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2Fc_JTFFAr5-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}